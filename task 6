import nltk
from nltk.util import ngrams
from nltk.lm import Laplace
from nltk.tokenize import word_tokenize
from nltk.lm.preprocessing import padded_everygram_pipeline
from collections import defaultdict

def ngram_smoothing_model(sentence, n):
    tokens = word_tokenize(sentence.lower())
    train_data, padded_sents = padded_everygram_pipeline(n, [tokens])
    model = Laplace(n)
    model.fit(train_data, padded_sents)
    return model

def predict_next_words(model, context, k=3):
    words_and_scores = defaultdict(float)
    for word in model.vocab:
        if word not in ['<s>', '</s>']:
            words_and_scores[word] = model.score(word, context)
            
    sorted_words = sorted(words_and_scores, key=words_and_scores.get, reverse=True)
    
    return sorted_words[:k]

sentence = input("Enter a sentence: ")
n = int(input("Enter the value of N for N-grams: "))

model = ngram_smoothing_model(sentence, n)

tokens = word_tokenize(sentence.lower())
if n > 1:
    context = tuple(tokens[-(n-1):])
else:
    context = tuple()

next_words = predict_next_words(model, context, k=3)
print("Next words:", ' '.join(next_words))